---
title: "Importar, explorar y limpiar datos"
author: "Nicolás Godoy Márquez"
date: "13-03-2022"
output: html_document
---
## 0. Objetivo del práctico

Este práctico tiene por objeto introducir a las y los estudiantes del curso en herramientas que les permitan a) **importar bases de datos en diversos formatos**; b)**explorar las variables** de las bases de datos importadas; y c) **exportar bases de datos** procesadas. Para ello, se trabajará con los paquetes `haven` (que forma parte, a su vez, del mundo de paquetes `tidyverse`), y `dplyr`, para poder importar  y exportar los datos, y manipular estos datos, respectivamente.

## 1. Recursos de la práctica

Para el correcto trabajo de estos materiales, deben descargar los datos de la *Encuesta de Caracterización Socioeconómica (CASEN)* en su versión 2020. Para ello, deben dirigirse al [siguiente enlace](https://drive.google.com/drive/folders/1Orgb3Qb9LcjTfjYMdIdy7SWd3xDMrTbG?usp=sharing), descargar el archivo en .zip y luego descomprimirlo en la carpeta _input/data_ de su repositorio. Para descomprimir los [archivos revisen](resource/unzipping/). Cuando lo hayan logrado verán la base en formato SPPS `Casen en Pandemia 2020 SPSS.sav` y en STATA `Casen en Pandemia 2020 SPSS.dta`

Recuerden siempre consultar el [**manual/libro de códigos**](http://observatorio.ministeriodesarrollosocial.gob.cl/storage/docs/casen/2020/Libro_de_codigos_Base_de_Datos_Casen_en_Pandemia_2020.pdf) antes de trabajar una base de datos.

## 2. Librerias a utilizar

En este práctico utilizaremos seis paquetes

1. `pacman`: este facilita y agiliza la lectura de los paquetes a utilizar en R

2. `sjmisc`: explorar datos

3. `tidyverse`: colección de paquetes, de la cual utilizaremos `dplyr` y `haven`

4. `dplyr`: nos permite seleccionar variables de un set de datos

5. `haven`: cargar y exportar bases de datos en formatos .sav y .dta

6. `readxl` y `writexl`: para cargar y exportar bases de datos en formato .xlsx y .xls


# Pasos del procesamiento

## 1. Cargar librerías

Dado que ya cargamos `pacman` en el práctico anterior, no lo debemos volver a instalar. Ahora bien, si  cargaremos los nuevos paquetes. Les recordamos que cuando luego de un paquete ponemos `::` esto se refiere a que se *"fuerza"* que esa función provenga de *ese paquete*

```{r packages, include=TRUE}
pacman::p_load(sjmisc,
               sjPlot,
               tidyverse,
               haven,
               readxl,
               writexl)
```

## 2. Importar datos

Para poder realizar análisis estadístico de cualquier tipo, el primer paso - sin considerar, por supuesto, la formulación de un problema de investigación, y la búsqueda de datos que permitan resolverlo - es **importar una base de datos**. Por razones obvias, si no hemos cargados los datos en el *entorno*, no seremos capaces de realizar ningún otro procedimiento, ni de preparación de los datos - por ejemplo, seleccionar variables, recodificarlas, construir variables sumativas, entre otros -, ni de análisis de estos - ya sean descriptivos, relacionales, explicativos, y así. 

Una de las bondades de **R** es que es posible importar y exportar fácilmente datos que se encuentren en *cualquier formato*: ya sea .csv, .dta, .sav, .xlsx y, por supuesto, .rds y .RData. Para poder hacerlo, sin embargo, lo primero es *instalar* y *cargar* las **librerías** que contienen las **funciones** necesarias para la importación de distintos tipos de archivos. 


### 2.1. Cargar set de datos

Una vez cargado el paquete `haven`, procedemos a *importar* los datos anteriormente mencionados. Para ello, en nuestro script, dejamos indicado que a partir de la lectura de los datos con `read_sav()`, crearemos un objeto llamado `datos`. Si este procedimiento se logra, esto aparecerá en el *Enviroment*.

```{r load, include=FALSE, warning= FALSE , message = F}
temp <- tempfile()
download.file("http://observatorio.ministeriodesarrollosocial.gob.cl/storage/docs/casen/2020/Casen_en_Pandemia_2020_SPSS.sav.zip",temp)
datos <- haven::read_sav(unz(temp, "Casen en Pandemia 2020 SPSS.sav"))
unlink(temp); remove(temp)
```

```{r, include= F}
casen <- datos 
```

Antes ¿dónde están nuestros datos? Por lo general, nuestros datos los dejaremos en la carpeta `input/data`. En el [siguiente enlace](https://drive.google.com/drive/folders/1Orgb3Qb9LcjTfjYMdIdy7SWd3xDMrTbG?usp=sharing) podrán descargar el archivo .zip que contiene la base de CASEN 2020. Si aún no sabes como descomprimir datos, por favor revisa [aquí](https://learn-r-udp.netlify.app/resource/unzipping/). 

Luego de que hayas **descargado y descomprimido los datos** asegurate de dejar el archivo `.sav` y `.dta` en la carpeta de tu proyecto `input/data`. Los datos tendrán distinto nombre según su formato: `Casen en Pandemia 2020 SPSS.sav` o `Casen en Pandemia 2020 SPSS.dta`.


{{< div "note" >}}
Para **importar** los datos en R debemos tener en consideración tres cosas:

1. Cómo se llaman los datos (en nuestro caso Casen en Pandemia 2020 SPSS)

2. El formato de nuestros datos (en nuestro caso .sav)

3. El lugar de donde están alojados nuestros datos. 
{{< /div >}}

El [paquete `haven`](https://haven.tidyverse.org/) tiene una serie de funciones para cargar datos llamadas `read_*` (luego del asterisco, debemos indicar el formato de los datos). Para ocuparlo solo debes tener en claro los puntos anteriores

`read_*("ruta_hacia_archivo/nombre_archivo.*"``. En nuestro caso:


```{r read, echo = T, eval = F}
datos <- read_sav("Casen en Pandemia 2020 SPSS.sav")  # No funciona
datos <- read_sav("input/data/casen en pandemia 2020 SPSS.sav") # No funciona
datos <- read_sav("input/data/Casen en Pandemia 2020 SPSS.sav") 
```

Los dos primeros comandos no funcionan porque

1. La ruta no está bien definida

2. El nombre de la base no es exacto

¡Dos errores muy frecuentes cuando uno se inicia! Ahora, ¿cómo sé si están bien los datos que acabo de cargar? Primero, notarás que en tu **Enviroment** se ha creado un objeto. En nuestro caso objeto posee `r format(ncol(datos), decimal.mark="," , big.mark = ".")` variables (columnas), y `r format( nrow(datos), decimal.mark="," , big.mark = ".")` filas (u observaciones)

¡Ahora es tu turno! Intenta hacer este procedimiento con los datos en `.dta`. También puedes encontrar este archivo en el enlace.

### 2.1.1 Cargar set de datos en otros formatos. 

Ahora bien, no siempre este procedimiento será tan fácil sobre todo pues no siempre vendrán en formatos "limpios". La gran forma de lidiar con eso es con la **manipulación de datos** (algo que nos tomará tiempo en este curso), pero de todas formas es de gran ayuda importar los datos de manera correcta, pues ello nos puede solucionar varios problemas de codificación y lectura. 

Para poder abordar esto de la mejor manera es necesario utilizar funciones *ad hoc* al formato de nuestros datos. Como se mencionó anteriormente, R es muy flexible en esto. En los siguientes pasos les mostraremos como cargar datos en otros formatos, reconociendo algunos de los *problemas comunes con los cuáles te encontrarás* (de seguro...)

#### a) `.dta`

Este es el formato específico de base de datos para STATA. Por ello, utilizaremos la función `read_dta()` (o `read_stata()`, que es lo mismo), incluida en el paquete `haven`.

```{r,echo = T, include=FALSE, eval = F}
datos <- read_dta("input/data/Casen en Pandemia 2020 SPSS.dta") 
```

#### b) .RData y .rds

¿Y R tiene formato de datos? ¡Sí! Como son propios del programa **no es necesario cargar paquetes**, pues las funciones para importarlos provienen del paquete `base`. La diferencia básica entre `.RData` y `.rds` es que `.rds` puede contener solo un objeto del *Enviroment* de R, mientras que `.RData` puede contener múltiples objetos que han sido guardados en el entorno (¡no sólo datos! también se guardarán gráficos, modelos, entre otros).

{{< div "note" >}}
*Leer un objeto proveniente de un archivo*

readRDS(file = "datos.rds")

*Leer múltiples objetos a un archivo*
load(file = "datos.RData")
{{</div>}}

Además de **nunca olvidar la ruta**, no debes olvidar una diferencia de codificación entre ambas funciones: con `load()` los objetos se cargan *automáticamente* en el ambiente, por lo cual no debemos utilizar operadores de asignación (`<-` o `=`) para crear un nuevo objeto, mientras que en `readRDS()` **sí debemos asignar un nuevo objeto en el ambiente**. 

```{r}
load(file = "input/data/CASEN.RData")
readRDS(file = "input/data/CASEN.rds")
```

```{r}
datos <- readRDS(file = "input/data/CASEN.rds")
```


¿Solo contiene datos? ¡No! Además de que puede contener múltiples datos, puede guardar otros *objetos* que se creen en su proceso estadístico. Por ejemplo, *modelos* ¡Lo veremos más adelante!

#### c) `.csv`

Los archivos en `.csv` o `.txt` son de frecuente uso dado que son más livianos que un archivo en `.dta` o `.sav` por el *meta-data* que contienen (información adicional, además de columnas-filas). El paquete `utils` de `R base` tiene una función de muy buena calidad llamada `read.table` (`read.csv()` para archivos en `.csv` y `read.delim()` para archivos en `.txt`)

Su estructura es muy simple `read.*(file = "datos.*")`. Ahora bien tiene una serie de argumentos que permiten leer de mejor manera los archivos **y de seguro los ocuparás**:

- [`sep`]: indica con qué están separadas las columnas (*; , -*)

- [`dec`]: indica como están separados los decimales (*. ,*)

- [`na-strings`]: indica como están codificados los `NA` (¡podría ser más de una forma!)

- [`encoding`]:puede ser `UTF-8` o `Latin-1`

- [`skip`]: indica el *número* de filas que hay que saltarse (no siempre los csv y excel parten en la primera fila). El argumento `nrow` indica el número de filas máximas a leer

- [`stringsAsFactors`]: si se indica verdadero (`TRUE`) los carácteres serán transformados en factores, lo cuál será muy útil en caso de necesitar hacer análisis.

```{r, eval = F}
datos <- read.csv("input/data/CASEN.csv", sep=",", 
                  encoding = "UTF-8", stringsAsFactors = F)

head(datos)
```

Muchos problemas, ¡vamos solucionado!

```{r, eval = F}
datos <- read.csv("input/data/CASEN.csv", sep=";", 
                  encoding = "Latin-1", stringsAsFactors = F, na.strings = c("No sabe", NA))

head(datos)
```


#### d) `.xlsx` 

A partir del paquete `readxl` de `tidyverse` podremos obtener datos que provienen de Excel (tanto en formato `.xls` como `.xlsx`). Ocuparemos la función `read_excel()`, la cual tiene argumentos similares a los que revisamos en `read.csv()`

{{< div "note" >}}
`read_excel("datos.xlsx", sheet = "Hoja 1", range = "A1:C40")`
`read_excel("datos.xlsx", sheet = 2, skip = 4, na = "No sabe")`
{{</div>}}

```{r}
datos <- readxl::read_excel(path = "input/data/CASEN.xlsx")
```

¡Hemos sido engañados/as! ¿Cómo solucionar?

```{r}
datos <- readxl::read_excel(path = "input/data/CASEN.xlsx", sheet = "Hoja1", skip = 1)

datos <- readxl::read_excel(path = "input/data/CASEN.xlsx", sheet = "Hoja1", skip = 1, na = "NA")

```

Para seguir con este ejercicio volvamos a utilizar la base original en `.dta`

```{r, eval = F }
datos <- read_dta("input/data/Casen en Pandemia 2020 SPSS.dta") 
```

```{r, include = F}
datos <- casen 
```


## 3. Explorar datos 

Lo más probable es que, una vez importados los datos a utilizar, no trabajemos con el total de variables incluidas en estos (que, en este caso, suman un total de *650* columnas ¡imaginen qué locura sería!). Es por ello que debemos **seleccionar** las variables de interés para resolver nuestro problema de investigación (sea el que sea). 

Antes de seleccionar las variables debemos **explorar nuestros datos**, si no ¿cómo saber qué seleccionar y qué no? En R base las funciones clásicas para explorar datos son

```{r eval = F}
View(datos) # Ver datos
names(datos) # Nombre de columnas
dim(datos) # Dimensiones
str(datos) # Estructura de los datos (las clases y categorias de repuesta)
```

A pesar de que son fáciles de aprender, no tienen una visualización muy amena. Un excelente paquete para explorar datos es `sjmisc`, que tiene tres funciones claves:

- [`View_df()`]: que en el visor "Viewer" les mostrará una tabla que tiene el nombre de variable, etiqueta y categorías de respuesta

- [`find_var()`]: que permite indagar en variables que estamos buscando según sus temáticas

- [`frq()`]: nos otorga la distribución univariada de variables categóricas que estamos explorando

- [`descr()`]: nos otorga estadísticos de tendencia central para la variable numérica seleccionada. 

*Ver datos en el visor de RStudio*
```{r, eval = F }
sjPlot::view_df(datos)
```

*Buscar variables sobre temáticas relacionadas a "vivienda" (no olvides dejarla entre comillas)*
```{r}
find_var(datos, "pobreza")
find_var(datos, "salario")
```

**Explorar distirbución de las variables**
```{r}
frq(datos$pobreza)
```

```{r , eval = F}
frq(datos$y1) #¡Qué feo!
```

```{r, echo= F }
head(frq(datos$y1)) #¡Qué feo!
```

Para las variables numeric, en cambio, podemos utilizar la función `descr()` del mismo paquete, que nos indicará las *medidas de tendencia central, dispersión y posición* de la variable.

```{r,echo = T, include=FALSE}
descr(datos$y1)
```


#### Sobre las clases de las variables

Un punto que ya se hace evidente de empezar a trabajar son como reconocer y trabajar **los distintos tipos de variables en R**. Si bien al inicio no es tan intuitivo ¡no te preocupes! Cuando uno avanza en el aprendizaje del programa de a poco estos conceptos se asimilan más. 

Partamos por lo básico que ustedes ya saben de sus cursos de estadística: **los niveles de medición**.  Sabemos que el nivel de medición de la variable *género* es *nominal* y, por lo tanto, sólo nos permite clasificar a unas personas u otras. Por ello, no podemos, por ejemplo, calcular el promedio del género de una muestra. Por otra parte, la variable *edad* presenta un nivel de medición *de razón*, por lo cual sí podemos realizar con ella operaciones aritméticas y, en consecuencia, es posible, por ejemplo, calcular el promedio de edad de la muestra con que estamos trabajando. 

Como revisamos en el práctico anterior La función `class()`, incluido en el *paquete base* de R, nos permite saber la *clase* de una variable determinada con la cual deseemos trabajar. También nos permite conocer la clase de otros objetos en R, pero no es algo que utilizaremos (aún).

#### En resumen:

| Clase  | Tipo de variable |
|---------:|:--------|
| `numeric` | Cuantitativa |
| `character` | Categórica |
| `Logic` |  Lógica (TRUE, FALSE, NA) |
| `factor` | Categórica con niveles y etiquetas |


## 3.1. Selección de variables

Luego de revisar el nivel de medición de las variables, y reconociendo la distribución de los datos que tenemos, es evidente que lo mejor es solamente trabajar con un *subconjunto* de los datos con las variables que queremos transformar. Si bien en el práctico 5 profundizaremos en la selección de variables, este es un primer adelanto que nos permitirá exportar datos que sólo contengan la información que nos interesa.

Para asegurarnos de saber exactamente qué variables queremos utilizar deberíamos ir al libro de códigos, pero también podemos elegir y decidir de manera más certera qué variables incorporar a partir de la revisión con `find_var()`. En esta sección no profundizaremos en distintas formas de seleccionar datos (¡ello lo veremos **a fondo** en el siguiente práctico!). Solo les mostraremos de manera simple cómo seleccionar algunas variables de nuestro interés:

- `ypchtotcor`: Ingresos del hogar
- `v13`: "Su hogar, ¿bajo qué situación ocupa la vivienda?"
- `v29`: "¿Cuántos dormitorios de uso exclusivo ocupa su hogar en esta vivienda?"
- `p6`: "¿Cuántas personas viven habitualmente en esta vivienda?"

Crearemos una base procesada llamada `datos_proc`, que sólo incluirá estas cuatro variables. 

```{r,echo = T, include=FALSE}
datos_proc <- select(datos, ypchtotcor,v13,v29,p6)
```

Como podemos ver en el ambiente (Environment), se creó un nuevo objeto llamado `datos_proc`, que tiene la misma cantidad de observaciones (filas) que datos, pero que sólo incluye 4 de las 650 variables iniciales. 

**IMPORTANTE**: objetos que tengan el mismo nombre **se sobreescriben**. Les recomendamos que, siempre que seleccionen variables (o que manipulen sus datos de cualquier manera), creen un objeto cuyo nombre sea distinto al original. Podemos, por ejemplo, incorporar el sufijo **_proc** como lo hicimos en este práctico.

## 4. Guardar y exportar datos

Por último, una vez que hayamos procesado los datos, es importante que los **guardemos** en una nueva base de datos procesada, para no tener que llevar a cabo el procesamiento otra vez.

Al igual que en el paso de carga de datos, y a partir del flujo de `input-R-output` propuesto, es esperable que estos datos procesados (o intermedios) los guardemos en `output/data`, pues son el resultado de un proceso de manipulación anterior (como pueden ser aquellos que realizamos en nuestro **código de procesamiento**)

El archivo se puede guardar en distintos formatos: 

### a) .RData y .rds


{{< div "note" >}}
*Guardar un objeto a un archivo*

saveRDS(objecto, file = "datos.rds")

*Guardar un objeto a un archivo*
save(objeto1, objeto2, file = "datos.RData)
{{</div>}}

Es lo recomendable, si el resto del análisis lo realizaremos en R. 

```{r,echo = T}
save(file = "output/data/datos_proc.RData") #Guardamos el objeto datos_proc en la ruta de trabajo actual, bajo el nombre de datos_proc.RData. 

saveRDS(datos_proc, file= "output/data/datos_proc.rds") #Guardamos el objeto datos_proc en la ruta de trabajo actual, bajo el nombre de datos_proc.rds. 
```

### b) .sav (`haven`)

```{r,echo = T}
write_sav(datos_proc, "output/data/datos_proc.sav") #Guardamos el objeto datos_proc en la ruta de trabajo actual, bajo el nombre de datos_proc.sav. 
```

### b) .dta (`haven`)

```{r,echo = T}
write_dta(datos_proc, "output/data/datos_proc.dta") #Guardamos el objeto datos_proc en la ruta de trabajo actual, bajo el nombre de datos_proc.dta. 
```

### b) .csv

```{r,echo = T}
write.csv(datos_proc, "output/data/datos_proc.csv") #Guardamos el objeto datos_proc en la ruta de trabajo actual, bajo el nombre de datos_proc.csv. 
```

### b) .xlsx

```{r,echo = T}
writexl::write_xlsx(datos_proc, "output/data/datos_proc.xlsx") #Guardamos el objeto datos_proc en la ruta de trabajo actual, bajo el nombre de datos_proc.xlsx. 
```

## Resumen

¡Eso es todo por este práctico! Aquí, aprendimos a: 
- 1) Importar datos en diferentes formatos.
- 2) Seleccionar variables (y hacer una revisión de ciertos aspectos de estas).
- 3) Guardar y exportar los datos procesados, en distintos formatos.

